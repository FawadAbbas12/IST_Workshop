{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SESSION_06.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Session 06 "
      ],
      "metadata": {
        "id": "lOyRJWsMoo4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time series & Natural Language Processing  <table class=\"tfo-notebook-buttons\" align=\"right\" style=\"margin-top:-55px\">\n",
        "  <td>\n",
        "      <a target=\"_blank\" href=\"https://keras.io/search.html?query=recurrent%20neural%20network\"><CNTER><img src=\"https://external-content.duckduckgo.com/iu/?u=http%3A%2F%2Fadventuresinmachinelearning.com%2Fwp-content%2Fuploads%2F2017%2F05%2Fkeras-logo-small-wb-1.png&f=1&nofb=1\"  width=\"50\" height=\"50\" /><p style='margin-left:12px'>KERAS</p></CENTER></a>\n",
        "  </td>\n",
        " </table>"
      ],
      "metadata": {
        "id": "u4ug91Z4or6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.python.keras.layers.core import Activation\n",
        "\n",
        "skip_plot =5  ### Plot strides\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/jenfly/opsd/master/opsd_germany_daily.csv'\n",
        "\n",
        "openpower_germany_df = pd.read_csv(url, sep=',', index_col=0, \n",
        "                             parse_dates=[0]) \n",
        "openpower_germany_df.tail()"
      ],
      "metadata": {
        "id": "uTQRmxLCutSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openpower_germany_df['Consumption'][::skip_plot].plot(marker='*')\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('electricity consumption')\n",
        "plt.show()\n",
        "consumption_energy = openpower_germany_df['Consumption'].to_numpy()\n",
        "print(consumption_energy.shape)"
      ],
      "metadata": {
        "id": "rkBgMsi62buX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### process the data for training and testing\n",
        "def make_data(time_series,step_x,step_y):\n",
        "    x = list()\n",
        "    Y = list()\n",
        "    for i in range(len(time_series)):\n",
        "        ind_x = i + step_x\n",
        "        ind_y = ind_x + step_y\n",
        "        if (ind_y>len(time_series)):  #as step_y can be big and bounding condition\n",
        "            break\n",
        "\n",
        "        seq_x, seq_y = time_series[i:ind_x], time_series[ind_x:ind_y]\n",
        "        x.append(seq_x)\n",
        "        Y.append(seq_y)\n",
        "    return x,Y\n",
        "\n",
        "step_x = 25\n",
        "step_y = 1\n",
        "\n",
        "x,Y = make_data(consumption_energy,step_x,step_y)\n",
        "x = np.array(x)\n",
        "Y = np.array(Y)\n",
        "feature_in = 1\n",
        "x = x.reshape(x.shape[0],x.shape[1],feature_in)\n",
        "print((x.shape,Y.shape))"
      ],
      "metadata": {
        "id": "pdNVFa2327yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### now we can apply different algorithms\n",
        "#Average\n",
        "def avg_baseline(x):\n",
        "    return np.mean(x,axis=1)\n",
        "\n",
        "Y_pred_avg = avg_baseline(x)\n",
        "\n",
        "\n",
        "plt.plot(Y[::skip_plot],alpha=0.5,color='r')\n",
        "plt.plot(Y_pred_avg[::skip_plot],'b.')\n",
        "plt.legend(['True','Avg-pred'])\n",
        "plt.show()\n",
        "r2_score(Y, Y_pred_avg)*100."
      ],
      "metadata": {
        "id": "ccYtaJb13bl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple RNN"
      ],
      "metadata": {
        "id": "xk-nIQl6unoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.SimpleRNN(100,activation='relu',input_shape=(step_x,feature_in)),\n",
        "    keras.layers.Dense(step_y)\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.005)\n",
        "model.compile(loss=\"mse\", optimizer=optimizer)\n",
        "history= model.fit(x,Y,epochs=10,verbose=0)\n",
        "loss = history.history[\"loss\"] \n",
        "plt.plot(loss, \"b.-\", label='Trainig Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JLqDEi4Wye6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x)\n",
        "print(f'Actual: {Y[0]} Prediction: {y_pred[0]}')"
      ],
      "metadata": {
        "id": "jjJHzb961A2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRU"
      ],
      "metadata": {
        "id": "ELk2mh019tB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.GRU(100,activation='relu',input_shape=(step_x,feature_in),return_sequences=True),\n",
        "    keras.layers.GRU(100,activation='relu',return_sequences=False),\n",
        "    keras.layers.Dense(step_y)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['mean_squared_error'])\n",
        "history= model.fit(x,Y,epochs=10,verbose=0)\n",
        "loss = history.history[\"loss\"] \n",
        "plt.plot(loss, \"b.-\", label='Trainig Loss')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YoaS5hZd93yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x)\n",
        "# print(r2_score(Y, Y_pred_avg)*100.)\n",
        "print(f'Actual: {Y[0]} Prediction: {y_pred[0]}')"
      ],
      "metadata": {
        "id": "4KhnlsRi-E1c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM"
      ],
      "metadata": {
        "id": "IWqYu_pl1r58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    keras.layers.LSTM(100,activation='relu',input_shape=(step_x,feature_in),return_sequences=True),\n",
        "    keras.layers.LSTM(100,activation='relu',return_sequences=False),\n",
        "    keras.layers.Dense(step_y)\n",
        "])\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=['mean_squared_error'])\n",
        "history= model.fit(x,Y,epochs=10,verbose=0)\n",
        "loss = history.history[\"loss\"] \n",
        "plt.plot(loss, \"b.-\", label='Trainig Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0nX7vUzK1ZKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x)\n",
        "print(f'Actual: {Y[0]} Prediction: {y_pred[0]}')"
      ],
      "metadata": {
        "id": "DIMB_be-8J6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transformer /huggingface *library*"
      ],
      "metadata": {
        "id": "Vy90xZXlP2LH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist\n",
        "!pip install transformers >/dev/null"
      ],
      "metadata": {
        "id": "_XvQpIg_QKWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### transformers Pipeline \n",
        "In the Transformers package, the pipeline is a wrapper class which preprocess input, predicts and post process output for other pipelines like Named Entity Recognition, Masked Language Modeling, Sentiment Analysis, Feature Extraction, Question Answering, etc.\n",
        "\n",
        "<code>  pipeline(\n",
        "                    'task_name',\n",
        "                    model ='model_name',\n",
        "                    tokenizer \n",
        "                )\n",
        "</code>\n",
        "<br>Some of aviailable models\n",
        "\n",
        "    feature-extraction (get the vector representation of a text)\n",
        "    fill-mask\n",
        "    ner (named entity recognition)\n",
        "    question-answering\n",
        "    sentiment-analysis\n",
        "    summarization\n",
        "    text-generation\n",
        "    translation\n",
        "    zero-shot-classification"
      ],
      "metadata": {
        "id": "2nIFZbz_TfRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "JeBSv9zUQTU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sentiment Analysis"
      ],
      "metadata": {
        "id": "x1vbftg0QYNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline('sentiment-analysis')"
      ],
      "metadata": {
        "id": "Z2VhxzRZQlxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = classifier(\"We are were happy wiht course content\")\n",
        "print(results)\n",
        "#######################################\n",
        "# exercise 1 Chage above text to get  #\n",
        "# a normal response                   #\n",
        "#######################################\n"
      ],
      "metadata": {
        "id": "VTO0qfV6Qo6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_output = results[0]['label']\n",
        "sentiment_score = results[0]['score']\n",
        "print(f'Sentiment is: {sentiment_output} and its score: {sentiment_score}')"
      ],
      "metadata": {
        "id": "ZkIJLhLRRBOz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question-answer NLP example"
      ],
      "metadata": {
        "id": "mk-PdEp0R22j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_answer = pipeline('question-answering')"
      ],
      "metadata": {
        "id": "zzYTN0ZvRqGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_a = question_answer({\n",
        "    'question': 'Who developed this library ?',\n",
        "    'context':'bot is created in the transformer library'\n",
        "})\n",
        "print(q_a)\n",
        "\n",
        "#######################################\n",
        "# exercise 1 Chage above text to get  #\n",
        "# answer for your question            #\n",
        "#######################################"
      ],
      "metadata": {
        "id": "bHFqMz-lR7HG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('The answer is', q_a['answer'])"
      ],
      "metadata": {
        "id": "PGjcYTUER_mh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Summarization"
      ],
      "metadata": {
        "id": "-FUNRiMYSYC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summary_ext = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
      ],
      "metadata": {
        "id": "lD6IUvYFSoA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\"This is a text summary test. We are going to see in this course if the text \n",
        "can be summarize efficiently. This section of IST course is about the NLP (natural language processing). In this course of AI which brings together \n",
        "computer science and statistics to harness that predictive power. Itâ€™s a must-have skill for all aspiring data analysts and data scientists, or anyone else who wants to wrestle all that raw data into refined trends and predictions.\"\"\"\n",
        "\n",
        "result = summary_ext(text)\n",
        "print(result)"
      ],
      "metadata": {
        "id": "YX6-eCF0Ss1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fill in the blank document processing"
      ],
      "metadata": {
        "id": "iZwMxB6QTHgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mask_complete = pipeline('fill-mask',model='bert-base-uncased')"
      ],
      "metadata": {
        "id": "BfgbJx39TInI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mask_complete(\"Aoa, i like to develop [MASK] model.\")\n",
        "#######################################\n",
        "# exercise 1 try multiple Mask        #\n",
        "#######################################"
      ],
      "metadata": {
        "id": "MWkEEi84TMN7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tips and Advance concepts ðŸ‘‡\n",
        "\n"
      ],
      "metadata": {
        "id": "9z4IAPmbFwF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Auto text completion."
      ],
      "metadata": {
        "id": "X5Tp5rQDpH1T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOwsuGQQY9OL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku \n",
        "import numpy as np \n",
        "\n",
        "%load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import datetime, os\n",
        "!mkdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t8VtxhQK0Js0"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer()\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt\n",
        "data = open('/tmp/sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences \n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9vH8Y59ajYL"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "callbacks = [\n",
        "            tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "]\n",
        "model.fit(predictors, label, epochs=25, verbose=2, callbacks=callbacks)"
      ],
      "metadata": {
        "id": "Bk42L6E50Phu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "FmYuA6sarNOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Vc6PHgxa6Hm"
      },
      "outputs": [],
      "source": [
        "def auto_complete(seed_text, next_words):\n",
        "\tfor _ in range(next_words):\n",
        "\t\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\t\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\t\tpredicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
        "\t\toutput_word = \"\"\n",
        "\t\tfor word, index in tokenizer.word_index.items():\n",
        "\t\t\tif index == predicted:\n",
        "\t\t\t\toutput_word = word\n",
        "\t\t\t\tbreak\n",
        "\t\tseed_text += \" \" + output_word\n",
        "\treturn seed_text\n",
        "\n",
        "print(auto_complete(\"towrad the end of era\", 5))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(auto_complete(\"i will be back\", 10))"
      ],
      "metadata": {
        "id": "yD2AU5bJtfuo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}